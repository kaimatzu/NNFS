{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Layers\n",
    "\n",
    "Neural networks become “deep” when they have 2 or more hidden layers. Layers between these endpoints have values that we don’t necessarily deal with, hence the name “hidden.”\n",
    "\n",
    "Input layer with 4 features into a hidden layer with 3 neurons:\n",
    "\n",
    "![Hidden Layer Diagram](./img/diagram%201.png)\n",
    "\n",
    "Samples (feature set data) get fed through the input, which does not change it in any way, to our first hidden layer, which we can see has 3 sets of weights, with 4 values each. \n",
    "\n",
    "Each of those 3 unique weight sets is associated with its distinct neuron. Thus, since we have 3 weight sets, we have 3 neurons in this first hidden layer. Each neuron has a unique set of weights, of which we have 4 (as there are 4 inputs to this layer), which is why our initial weights have a shape of *(3,4)*.\n",
    "\n",
    "### Adding another layer\n",
    "\n",
    "To add another layer, we must make sure that the expected input to that layer matches the previous layer’s output.\n",
    "\n",
    "In the example, the previous layer has 3 weight sets and 3 biases, so we know it has 3 neurons. So for the next layer, we can have as many weight sets as we want (because this is how many neurons this new layer will have), but each of those weight sets must have 3 discrete weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5031  -1.04185 -2.03875]\n",
      " [ 0.2434  -2.7332  -5.7633 ]\n",
      " [-0.99314  1.41254 -0.35655]]\n"
     ]
    }
   ],
   "source": [
    "inputs = [\n",
    "    [1.0, 2.0, 3.0, 2.5],\n",
    "    [2.0, 5.0, -1.0, 2.0],\n",
    "    [-1.5, 2.7, 3.3, -0.8]\n",
    "] \n",
    "weights = [\n",
    "    [0.2, 0.8, -0.5, 1.0], \n",
    "    [0.5, -0.91, 0.26, -0.5], \n",
    "    [-0.26, -0.27, 0.17, 0.87]\n",
    "] \n",
    "biases = [2, 3, 0.5]\n",
    "weights2 = [\n",
    "    [0.1, -0.14, 0.5], \n",
    "    [-0.5, 0.12, -0.33], \n",
    "    [-0.44, 0.73, -0.13]\n",
    "]\n",
    "biases2 = [-1, 2, -0.5]\n",
    "\n",
    "# Hidden Layer 1 - Original inputs\n",
    "layer1_outputs = np.dot(inputs, np.array(weights).T) + biases\n",
    "\n",
    "# Hidden Layer 2 - Taking in output from previous hidden layer as input\n",
    "layer2_outputs = np.dot(layer1_outputs, np.array(weights2).T) + biases2\n",
    "\n",
    "print(layer2_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, our neural network could be visually represented as:\n",
    "\n",
    "![Hidden Layer Diagram 2](./img/diagram%202.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
